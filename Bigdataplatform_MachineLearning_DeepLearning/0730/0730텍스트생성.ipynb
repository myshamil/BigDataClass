{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596070599131",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"들판에 있는 말이 뛰고 있다\n",
    "그의 말이 법이다\n",
    "가는 말이 고와야 오는 말이 곱다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'말이': 1,\n '들판에': 2,\n '있는': 3,\n '뛰고': 4,\n '있다': 5,\n '그의': 6,\n '법이다': 7,\n '가는': 8,\n '고와야': 9,\n '오는': 10,\n '곱다': 11}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize =len(t.word_index)+1 #11 (0~10 ->1~11) 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
    }
   ],
   "source": [
    "# 트레이닝 데이터 생성\n",
    "sequences=[]\n",
    "for line in text.split(\"\\n\") :\n",
    "    encoded =t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence=encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = max(len(s) for s in sequences) #최대 길이 6\n",
    "#입력크기를 동일하게 해주기 위해 패딩 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences= pad_sequences(sequences, maxlen= maxLen, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 3,  1,  4,  5,  1,  7,  1,  9, 10,  1, 11])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "x= sequences[:,:-1] #마지막 열을 제외한 \n",
    "y= sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y, num_classes=vocabSize) #원핫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, SimpleRNN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/200\n1/1 [==============================] - 0s 998us/step - loss: 2.4824 - accuracy: 0.1818\nEpoch 2/200\n1/1 [==============================] - 0s 0s/step - loss: 2.4705 - accuracy: 0.1818\nEpoch 3/200\n1/1 [==============================] - 0s 997us/step - loss: 2.4584 - accuracy: 0.1818\nEpoch 4/200\n1/1 [==============================] - 0s 997us/step - loss: 2.4461 - accuracy: 0.1818\nEpoch 5/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.4334 - accuracy: 0.1818\nEpoch 6/200\n1/1 [==============================] - 0s 0s/step - loss: 2.4204 - accuracy: 0.3636\nEpoch 7/200\n1/1 [==============================] - 0s 998us/step - loss: 2.4068 - accuracy: 0.3636\nEpoch 8/200\n1/1 [==============================] - 0s 997us/step - loss: 2.3927 - accuracy: 0.4545\nEpoch 9/200\n1/1 [==============================] - 0s 1ms/step - loss: 2.3780 - accuracy: 0.4545\nEpoch 10/200\n1/1 [==============================] - 0s 996us/step - loss: 2.3625 - accuracy: 0.4545\nEpoch 11/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.3463 - accuracy: 0.4545\nEpoch 12/200\n1/1 [==============================] - 0s 998us/step - loss: 2.3292 - accuracy: 0.4545\nEpoch 13/200\n1/1 [==============================] - 0s 997us/step - loss: 2.3112 - accuracy: 0.4545\nEpoch 14/200\n1/1 [==============================] - 0s 997us/step - loss: 2.2923 - accuracy: 0.4545\nEpoch 15/200\n1/1 [==============================] - 0s 0s/step - loss: 2.2725 - accuracy: 0.4545\nEpoch 16/200\n1/1 [==============================] - 0s 999us/step - loss: 2.2516 - accuracy: 0.4545\nEpoch 17/200\n1/1 [==============================] - 0s 997us/step - loss: 2.2297 - accuracy: 0.4545\nEpoch 18/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.2068 - accuracy: 0.3636\nEpoch 19/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.1831 - accuracy: 0.3636\nEpoch 20/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.1586 - accuracy: 0.3636\nEpoch 21/200\n1/1 [==============================] - 0s 998us/step - loss: 2.1334 - accuracy: 0.3636\nEpoch 22/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.1078 - accuracy: 0.3636\nEpoch 23/200\n1/1 [==============================] - 0s 998us/step - loss: 2.0820 - accuracy: 0.3636\nEpoch 24/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.0562 - accuracy: 0.3636\nEpoch 25/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.0307 - accuracy: 0.3636\nEpoch 26/200\n1/1 [==============================] - 0s 2ms/step - loss: 2.0058 - accuracy: 0.3636\nEpoch 27/200\n1/1 [==============================] - 0s 998us/step - loss: 1.9819 - accuracy: 0.3636\nEpoch 28/200\n1/1 [==============================] - 0s 998us/step - loss: 1.9592 - accuracy: 0.3636\nEpoch 29/200\n1/1 [==============================] - 0s 998us/step - loss: 1.9378 - accuracy: 0.3636\nEpoch 30/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.9180 - accuracy: 0.3636\nEpoch 31/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.8997 - accuracy: 0.3636\nEpoch 32/200\n1/1 [==============================] - 0s 997us/step - loss: 1.8828 - accuracy: 0.3636\nEpoch 33/200\n1/1 [==============================] - 0s 998us/step - loss: 1.8670 - accuracy: 0.3636\nEpoch 34/200\n1/1 [==============================] - 0s 996us/step - loss: 1.8520 - accuracy: 0.3636\nEpoch 35/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.8375 - accuracy: 0.3636\nEpoch 36/200\n1/1 [==============================] - 0s 997us/step - loss: 1.8230 - accuracy: 0.3636\nEpoch 37/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.8082 - accuracy: 0.3636\nEpoch 38/200\n1/1 [==============================] - 0s 997us/step - loss: 1.7929 - accuracy: 0.3636\nEpoch 39/200\n1/1 [==============================] - 0s 997us/step - loss: 1.7770 - accuracy: 0.3636\nEpoch 40/200\n1/1 [==============================] - 0s 997us/step - loss: 1.7605 - accuracy: 0.3636\nEpoch 41/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.7433 - accuracy: 0.3636\nEpoch 42/200\n1/1 [==============================] - 0s 997us/step - loss: 1.7255 - accuracy: 0.3636\nEpoch 43/200\n1/1 [==============================] - 0s 996us/step - loss: 1.7073 - accuracy: 0.4545\nEpoch 44/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.6888 - accuracy: 0.4545\nEpoch 45/200\n1/1 [==============================] - 0s 998us/step - loss: 1.6700 - accuracy: 0.4545\nEpoch 46/200\n1/1 [==============================] - 0s 998us/step - loss: 1.6511 - accuracy: 0.4545\nEpoch 47/200\n1/1 [==============================] - 0s 997us/step - loss: 1.6319 - accuracy: 0.4545\nEpoch 48/200\n1/1 [==============================] - 0s 997us/step - loss: 1.6126 - accuracy: 0.4545\nEpoch 49/200\n1/1 [==============================] - 0s 997us/step - loss: 1.5932 - accuracy: 0.4545\nEpoch 50/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.5735 - accuracy: 0.4545\nEpoch 51/200\n1/1 [==============================] - 0s 998us/step - loss: 1.5535 - accuracy: 0.4545\nEpoch 52/200\n1/1 [==============================] - 0s 997us/step - loss: 1.5333 - accuracy: 0.4545\nEpoch 53/200\n1/1 [==============================] - 0s 998us/step - loss: 1.5128 - accuracy: 0.4545\nEpoch 54/200\n1/1 [==============================] - 0s 997us/step - loss: 1.4921 - accuracy: 0.5455\nEpoch 55/200\n1/1 [==============================] - 0s 997us/step - loss: 1.4711 - accuracy: 0.5455\nEpoch 56/200\n1/1 [==============================] - 0s 997us/step - loss: 1.4500 - accuracy: 0.5455\nEpoch 57/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.4288 - accuracy: 0.5455\nEpoch 58/200\n1/1 [==============================] - 0s 998us/step - loss: 1.4075 - accuracy: 0.6364\nEpoch 59/200\n1/1 [==============================] - 0s 997us/step - loss: 1.3862 - accuracy: 0.6364\nEpoch 60/200\n1/1 [==============================] - 0s 997us/step - loss: 1.3650 - accuracy: 0.6364\nEpoch 61/200\n1/1 [==============================] - 0s 997us/step - loss: 1.3438 - accuracy: 0.6364\nEpoch 62/200\n1/1 [==============================] - 0s 997us/step - loss: 1.3228 - accuracy: 0.6364\nEpoch 63/200\n1/1 [==============================] - 0s 997us/step - loss: 1.3020 - accuracy: 0.6364\nEpoch 64/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.2813 - accuracy: 0.6364\nEpoch 65/200\n1/1 [==============================] - 0s 997us/step - loss: 1.2609 - accuracy: 0.6364\nEpoch 66/200\n1/1 [==============================] - 0s 998us/step - loss: 1.2407 - accuracy: 0.6364\nEpoch 67/200\n1/1 [==============================] - 0s 997us/step - loss: 1.2207 - accuracy: 0.6364\nEpoch 68/200\n1/1 [==============================] - 0s 998us/step - loss: 1.2009 - accuracy: 0.6364\nEpoch 69/200\n1/1 [==============================] - 0s 997us/step - loss: 1.1814 - accuracy: 0.6364\nEpoch 70/200\n1/1 [==============================] - 0s 998us/step - loss: 1.1622 - accuracy: 0.6364\nEpoch 71/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.1432 - accuracy: 0.6364\nEpoch 72/200\n1/1 [==============================] - 0s 998us/step - loss: 1.1245 - accuracy: 0.6364\nEpoch 73/200\n1/1 [==============================] - 0s 997us/step - loss: 1.1060 - accuracy: 0.6364\nEpoch 74/200\n1/1 [==============================] - 0s 997us/step - loss: 1.0879 - accuracy: 0.6364\nEpoch 75/200\n1/1 [==============================] - 0s 996us/step - loss: 1.0700 - accuracy: 0.6364\nEpoch 76/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.0524 - accuracy: 0.6364\nEpoch 77/200\n1/1 [==============================] - 0s 997us/step - loss: 1.0350 - accuracy: 0.6364\nEpoch 78/200\n1/1 [==============================] - 0s 997us/step - loss: 1.0179 - accuracy: 0.6364\nEpoch 79/200\n1/1 [==============================] - 0s 2ms/step - loss: 1.0011 - accuracy: 0.6364\nEpoch 80/200\n1/1 [==============================] - 0s 997us/step - loss: 0.9844 - accuracy: 0.6364\nEpoch 81/200\n1/1 [==============================] - 0s 997us/step - loss: 0.9681 - accuracy: 0.6364\nEpoch 82/200\n1/1 [==============================] - 0s 998us/step - loss: 0.9519 - accuracy: 0.6364\nEpoch 83/200\n1/1 [==============================] - 0s 998us/step - loss: 0.9360 - accuracy: 0.6364\nEpoch 84/200\n1/1 [==============================] - 0s 997us/step - loss: 0.9203 - accuracy: 0.6364\nEpoch 85/200\n1/1 [==============================] - 0s 997us/step - loss: 0.9047 - accuracy: 0.6364\nEpoch 86/200\n1/1 [==============================] - 0s 997us/step - loss: 0.8894 - accuracy: 0.7273\nEpoch 87/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.8743 - accuracy: 0.7273\nEpoch 88/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.8594 - accuracy: 0.7273\nEpoch 89/200\n1/1 [==============================] - 0s 998us/step - loss: 0.8446 - accuracy: 0.8182\nEpoch 90/200\n1/1 [==============================] - 0s 997us/step - loss: 0.8301 - accuracy: 0.8182\nEpoch 91/200\n1/1 [==============================] - 0s 997us/step - loss: 0.8157 - accuracy: 0.8182\nEpoch 92/200\n1/1 [==============================] - 0s 997us/step - loss: 0.8015 - accuracy: 0.8182\nEpoch 93/200\n1/1 [==============================] - 0s 997us/step - loss: 0.7875 - accuracy: 0.8182\nEpoch 94/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.7736 - accuracy: 0.8182\nEpoch 95/200\n1/1 [==============================] - 0s 997us/step - loss: 0.7599 - accuracy: 0.8182\nEpoch 96/200\n1/1 [==============================] - 0s 998us/step - loss: 0.7464 - accuracy: 0.8182\nEpoch 97/200\n1/1 [==============================] - 0s 997us/step - loss: 0.7330 - accuracy: 0.8182\nEpoch 98/200\n1/1 [==============================] - 0s 997us/step - loss: 0.7198 - accuracy: 0.8182\nEpoch 99/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.8182\nEpoch 100/200\n1/1 [==============================] - 0s 997us/step - loss: 0.6937 - accuracy: 0.8182\nEpoch 101/200\n1/1 [==============================] - 0s 997us/step - loss: 0.6809 - accuracy: 0.8182\nEpoch 102/200\n1/1 [==============================] - 0s 997us/step - loss: 0.6683 - accuracy: 0.8182\nEpoch 103/200\n1/1 [==============================] - 0s 998us/step - loss: 0.6557 - accuracy: 0.8182\nEpoch 104/200\n1/1 [==============================] - 0s 998us/step - loss: 0.6433 - accuracy: 0.8182\nEpoch 105/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.8182\nEpoch 106/200\n1/1 [==============================] - 0s 997us/step - loss: 0.6190 - accuracy: 0.8182\nEpoch 107/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.8182\nEpoch 108/200\n1/1 [==============================] - 0s 997us/step - loss: 0.5951 - accuracy: 0.8182\nEpoch 109/200\n1/1 [==============================] - 0s 998us/step - loss: 0.5834 - accuracy: 0.8182\nEpoch 110/200\n1/1 [==============================] - 0s 997us/step - loss: 0.5719 - accuracy: 0.8182\nEpoch 111/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.8182\nEpoch 112/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.9091\nEpoch 113/200\n1/1 [==============================] - 0s 997us/step - loss: 0.5379 - accuracy: 1.0000\nEpoch 114/200\n1/1 [==============================] - 0s 997us/step - loss: 0.5269 - accuracy: 1.0000\nEpoch 115/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 1.0000\nEpoch 116/200\n1/1 [==============================] - 0s 997us/step - loss: 0.5052 - accuracy: 1.0000\nEpoch 117/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 1.0000\nEpoch 118/200\n1/1 [==============================] - 0s 998us/step - loss: 0.4841 - accuracy: 1.0000\nEpoch 119/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 1.0000\nEpoch 120/200\n1/1 [==============================] - 0s 997us/step - loss: 0.4635 - accuracy: 1.0000\nEpoch 121/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 1.0000\nEpoch 122/200\n1/1 [==============================] - 0s 997us/step - loss: 0.4435 - accuracy: 1.0000\nEpoch 123/200\n1/1 [==============================] - 0s 998us/step - loss: 0.4338 - accuracy: 1.0000\nEpoch 124/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 1.0000\nEpoch 125/200\n1/1 [==============================] - 0s 998us/step - loss: 0.4146 - accuracy: 1.0000\nEpoch 126/200\n1/1 [==============================] - 0s 998us/step - loss: 0.4053 - accuracy: 1.0000\nEpoch 127/200\n1/1 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 1.0000\nEpoch 128/200\n1/1 [==============================] - 0s 998us/step - loss: 0.3870 - accuracy: 1.0000\nEpoch 129/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 1.0000\nEpoch 130/200\n1/1 [==============================] - 0s 997us/step - loss: 0.3694 - accuracy: 1.0000\nEpoch 131/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 1.0000\nEpoch 132/200\n1/1 [==============================] - 0s 997us/step - loss: 0.3523 - accuracy: 1.0000\nEpoch 133/200\n1/1 [==============================] - 0s 997us/step - loss: 0.3440 - accuracy: 1.0000\nEpoch 134/200\n1/1 [==============================] - 0s 998us/step - loss: 0.3359 - accuracy: 1.0000\nEpoch 135/200\n1/1 [==============================] - 0s 997us/step - loss: 0.3279 - accuracy: 1.0000\nEpoch 136/200\n1/1 [==============================] - 0s 997us/step - loss: 0.3200 - accuracy: 1.0000\nEpoch 137/200\n1/1 [==============================] - 0s 997us/step - loss: 0.3123 - accuracy: 1.0000\nEpoch 138/200\n1/1 [==============================] - 0s 997us/step - loss: 0.3048 - accuracy: 1.0000\nEpoch 139/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2974 - accuracy: 1.0000\nEpoch 140/200\n1/1 [==============================] - 0s 998us/step - loss: 0.2902 - accuracy: 1.0000\nEpoch 141/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 1.0000\nEpoch 142/200\n1/1 [==============================] - 0s 998us/step - loss: 0.2761 - accuracy: 1.0000\nEpoch 143/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2694 - accuracy: 1.0000\nEpoch 144/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2627 - accuracy: 1.0000\nEpoch 145/200\n1/1 [==============================] - 0s 998us/step - loss: 0.2563 - accuracy: 1.0000\nEpoch 146/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2499 - accuracy: 1.0000\nEpoch 147/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2437 - accuracy: 1.0000\nEpoch 148/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 1.0000\nEpoch 149/200\n1/1 [==============================] - 0s 998us/step - loss: 0.2318 - accuracy: 1.0000\nEpoch 150/200\n1/1 [==============================] - 0s 998us/step - loss: 0.2261 - accuracy: 1.0000\nEpoch 151/200\n1/1 [==============================] - 0s 998us/step - loss: 0.2205 - accuracy: 1.0000\nEpoch 152/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2150 - accuracy: 1.0000\nEpoch 153/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2097 - accuracy: 1.0000\nEpoch 154/200\n1/1 [==============================] - 0s 997us/step - loss: 0.2046 - accuracy: 1.0000\nEpoch 155/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 1.0000\nEpoch 156/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 1.0000\nEpoch 157/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1899 - accuracy: 1.0000\nEpoch 158/200\n1/1 [==============================] - 0s 998us/step - loss: 0.1853 - accuracy: 1.0000\nEpoch 159/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 1.0000\nEpoch 160/200\n1/1 [==============================] - 0s 998us/step - loss: 0.1764 - accuracy: 1.0000\nEpoch 161/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1722 - accuracy: 1.0000\nEpoch 162/200\n1/1 [==============================] - 0s 998us/step - loss: 0.1680 - accuracy: 1.0000\nEpoch 163/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 1.0000\nEpoch 164/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1602 - accuracy: 1.0000\nEpoch 165/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1564 - accuracy: 1.0000\nEpoch 166/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1527 - accuracy: 1.0000\nEpoch 167/200\n1/1 [==============================] - 0s 998us/step - loss: 0.1492 - accuracy: 1.0000\nEpoch 168/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1457 - accuracy: 1.0000\nEpoch 169/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1424 - accuracy: 1.0000\nEpoch 170/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 1.0000\nEpoch 171/200\n1/1 [==============================] - 0s 998us/step - loss: 0.1360 - accuracy: 1.0000\nEpoch 172/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1330 - accuracy: 1.0000\nEpoch 173/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 1.0000\nEpoch 174/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1272 - accuracy: 1.0000\nEpoch 175/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1244 - accuracy: 1.0000\nEpoch 176/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 1.0000\nEpoch 177/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1192 - accuracy: 1.0000\nEpoch 178/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 1.0000\nEpoch 179/200\n1/1 [==============================] - 0s 998us/step - loss: 0.1142 - accuracy: 1.0000\nEpoch 180/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1118 - accuracy: 1.0000\nEpoch 181/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1095 - accuracy: 1.0000\nEpoch 182/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1073 - accuracy: 1.0000\nEpoch 183/200\n1/1 [==============================] - 0s 998us/step - loss: 0.1051 - accuracy: 1.0000\nEpoch 184/200\n1/1 [==============================] - 0s 997us/step - loss: 0.1030 - accuracy: 1.0000\nEpoch 185/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 1.0000\nEpoch 186/200\n1/1 [==============================] - 0s 997us/step - loss: 0.0990 - accuracy: 1.0000\nEpoch 187/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 1.0000\nEpoch 188/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 1.0000\nEpoch 189/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 1.0000\nEpoch 190/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 1.0000\nEpoch 191/200\n1/1 [==============================] - 0s 997us/step - loss: 0.0900 - accuracy: 1.0000\nEpoch 192/200\n1/1 [==============================] - 0s 997us/step - loss: 0.0883 - accuracy: 1.0000\nEpoch 193/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 1.0000\nEpoch 194/200\n1/1 [==============================] - 0s 996us/step - loss: 0.0852 - accuracy: 1.0000\nEpoch 195/200\n1/1 [==============================] - 0s 998us/step - loss: 0.0836 - accuracy: 1.0000\nEpoch 196/200\n1/1 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 1.0000\nEpoch 197/200\n1/1 [==============================] - 0s 998us/step - loss: 0.0807 - accuracy: 1.0000\nEpoch 198/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 1.0000\nEpoch 199/200\n1/1 [==============================] - 0s 997us/step - loss: 0.0780 - accuracy: 1.0000\nEpoch 200/200\n1/1 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 1.0000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x26156bfcd88>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, 10, input_length=maxLen-1)) #x데이터 y데이터 분리해서 -1 \n",
    "#임베딩벡터의 차원은 10\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocabSize, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x,y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'들판에 있는 말이 뛰고 있다'"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "def sentence_generation(model, t, cw, n):\n",
    "    #문장 예측 생성\n",
    "    initWord = cw #시작단어 저장\n",
    "    sentence =''\n",
    "    for _ in range(n):\n",
    "        #4번 반복\n",
    "        #_ : 변수가 없다. \n",
    "        # print(t.texts_to_sequences([cw]))\n",
    "        encoded = t.texts_to_sequences([cw])[0]\n",
    "        encoded =pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        # print(encoded)\n",
    "        result = model.predict_classes(encoded)\n",
    "        # print(result)\n",
    "        for word, index in t.word_index.items():\n",
    "            if index==result:\n",
    "                break\n",
    "        cw=cw+\" \"+ word #\"들판에 있는\"\n",
    "        sentence = sentence+\" \"+ word\n",
    "    sentence=initWord+sentence\n",
    "    return sentence\n",
    "\n",
    "sentence_generation(model, t, '들판에', 4)"
   ]
  }
 ]
}